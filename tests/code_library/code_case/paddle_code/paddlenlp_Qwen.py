import paddle
import paddlenlp
print('#########################case1#########################')


def _add_tokens(self, new_tokens: Union[List[str], List[paddlenlp.
    transformers.AddedToken]]) ->int:
    return paddle.zeros(shape=[2, 4])


print('#########################case2#########################')


def chat(self, system: str='You are a helpful assistant.',
    generation_config: Optional[paddlenlp.generation.GenerationConfig]=None):
    return paddle.zeros(shape=[2, 4])


print('#########################case3#########################')
paddle.utils.try_import('logging')
logger = logging.getLogger(name=__name__)
print('#########################case4#########################')
paddlenlp.transformers.model_outputs.BaseModelOutputWithPast(last_hidden_state
    =hidden_states, past_key_values=presents, hidden_states=
    all_hidden_states, attentions=all_self_attentions)
print('#########################case5#########################')
paddlenlp.transformers.model_outputs.CausalLMOutputWithPast(loss=loss,
    logits=lm_logits, past_key_values=transformer_outputs.past_key_values,
    hidden_states=transformer_outputs.hidden_states, attentions=
    transformer_outputs.attentions)
